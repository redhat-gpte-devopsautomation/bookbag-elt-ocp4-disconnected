:GUID: %guid%
:OSP_DOMAIN: %dns_zone%
:GITLAB_URL: %gitlab_url%
:GITLAB_USERNAME: %gitlab_username%
:GITLAB_PASSWORD: %gitlab_password%
:GITLAB_HOST: %gitlab_hostname%
:TOWER_URL: %tower_url%
:TOWER_ADMIN_USER: %tower_admin_user%
:TOWER_ADMIN_PASSWORD: %tower_admin_password%
:SSH_COMMAND: %ssh_command%
:SSH_PASSWORD: %ssh_password%
:VSCODE_UI_URL: %vscode_ui_url%
:VSCODE_UI_PASSWORD: %vscode_ui_password%
:organization_name: Default
:gitlab_project: ansible/gitops-lab
:project_prod: Project gitOps - Prod
:project_test: Project gitOps - Test
:inventory_prod: GitOps inventory - Prod Env
:inventory_test: GitOps inventory - Test Env
:credential_machine: host_credential
:credential_git: gitlab_credential
:credential_git_token: gitlab_token 
:credential_openstack: cloud_credential
:jobtemplate_prod: App deployer - Prod Env
:jobtemplate_test: App deployer - Test Env
:source-linenums-option:        
:markup-in-source: verbatim,attributes,quotes
:show_solution: true
:catalog_name: OpenShift 4 Advanced Infra Deploy ILT
:course_name: Advanced Red Hat OpenShift Container Platform Deployment and Management
:opentlc_portal: link:https://labs.opentlc.com/[OPENTLC lab portal^]
:opentlc_account_management: link:https://www.opentlc.com/account/[OPENTLC Account Management page^]
:opentlc_catalog_name: OPENTLC OpenShift 4 Labs
:opentlc_catalog_item_name_aws: OpenShift 4 Advanced Infra Deploy ILT
:ocp4_docs: link:https://docs.openshift.com/container-platform/4.11/welcome/index.html[OpenShift Container Platform Documentation]

== Prepare Environment

To prepare your environment, think of all of the things that you will need to do in order to install OpenShift in a restricted network environment.
You can get more background on Restricted Network installations in the OpenShift documentation.
When you have a chance, read link:https://docs.openshift.com/container-platform/4.11/installing/disconnected_install/index.html[restricted network installation documentation^].

Keep in mind what you need to accomplish on this restricted network install:

[cols="1a",grid=none,width=100%]
|===
^| image::images/disconnected_install.png[]
^| Figure 1 - Disconnected install
|===

=== Configure Bastion VM

Your bastion VM is your entry point to the disconnected environment.
Sometimes it is referred to as a "jump host".
It is the only node you can SSH directly into from outside of the lab environment.
It is where you will perform the majority of your activities in these labs throughout the week.
As you prepare this host, think about the things you will do from it during an installation.

You will:

* Install AWS command line tools.
* Configure AWS credentials and test them.
* Install OCP command line tools.

. SSH to your `bastion` VM.
Use the credentials and instructions you received in your provisioning email to connect.
+
WARNING: Unless otherwise specified, *you must do everything as your 'lab-user' username*.
There is no reason to be root.
If you try to do all of these exercises as root and use the hints and commands in this lab guide, you will fail.

. You'll need the AWS command line tools to manage AWS resources.
Download it an install it as root on your bastion.
+
[source,sh]
----
sudo -i
echo ${GUID}

# Download the latest AWS Command Line Interface
curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
unzip awscli-bundle.zip

# Install the AWS CLI into /bin/aws
./awscli-bundle/install -i /usr/local/aws -b /bin/aws

# Validate that the AWS CLI works
aws --version

# Clean up downloaded files
rm -rf /root/awscli-bundle /root/awscli-bundle.zip

# Return to your 'lab-user' user
exit
----

. Save your provided AWS credentials to the `$HOME/.aws/credentials` file, making sure to replace `YOURACCESSKEY` and `YOURSECRETACCESSKEY` with your individual credentials:

.. Get your AWS credentials from the final lab provisioning email.
+
IMPORTANT: Do NOT select `us-east-1`.
+
[source,sh]
----
export AWSKEY=<YOURACCESSKEY>
export AWSSECRETKEY=<YOURSECRETKEY>
export REGION=us-east-2

mkdir $HOME/.aws
cat << EOF >>  $HOME/.aws/credentials
[default]
aws_access_key_id = ${AWSKEY}
aws_secret_access_key = ${AWSSECRETKEY}
region = $REGION
EOF
----

. Put your $REGION value into your `.bashrc` so it'll be available throughout the lab.
+
[source,sh]
----
ansible localhost -m lineinfile -a "path=$HOME/.bashrc regexp='^export REGION' line='export REGION=${REGION}'"
source $HOME/.bashrc
----

. Check to see that your credentials work:
+
[source,sh]
----
aws sts get-caller-identity
----
+
.Sample Output
[source,texinfo]
----
{
    "Account": "OMIT",
    "UserId": "OMIT",
    "Arn": "arn:aws:iam::657952645207:user/wkulhane@redhat.com-b91e"
}
----

. On your bastion set an environment variable OCP_RELEASE.
This will be used throughout this lab to determine the version of OpenShift you want to install.
It will make some future commands easier to run.
This uses the Ansible `lininfile` module.
It helps ensure you add to your `.bashrc`, but do not add duplicate entries.
+
[source,sh]
----
ansible localhost -m lineinfile -a 'path=$HOME/.bashrc regexp="^export OCP_RELEASE" line="export OCP_RELEASE=4.11.11"'
source $HOME/.bashrc
----
// !!!!!!!!!!
// IF YOU CHANGE THE RELEASE VERSION, UPDATE THE SAMPLE OUTPUTS FOR PAYLOAD AND VERSION IN THIS LAB!!!!!!!!
// !!!!!!!!!!

. Download and extract the OpenShift CLI, or `oc` client, to your `bastion`.
This client will be used extensively throughout the course for activities such as mirroring images for installation to controlling your cluster and workloads once deployed.
The `oc` client is very similar to the `kubectl` client, but is more powerful and user friendly when used with OpenShift.
+
[source,sh]
----
wget https://mirror.openshift.com/pub/openshift-v4/clients/ocp/$OCP_RELEASE/openshift-client-linux-$OCP_RELEASE.tar.gz
----
+
.Sample Output
[source,sh,options="nowrap"]
----
--2022-11-25 11:16:32--  https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.11.11/openshift-client-linux-4.11.11.tar.gz
Resolving mirror.openshift.com (mirror.openshift.com)... 18.160.46.23, 18.160.46.42, 18.160.46.73, ...
Connecting to mirror.openshift.com (mirror.openshift.com)|18.160.46.23|:443... connected.
HTTP request sent, awaiting response... 307 S3Redirect
Location: https://art-srv-enterprise.s3.amazonaws.com/pub/openshift-v4/x86_64/clients/ocp/4.11.11/openshift-client-linux-4.11.11.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYV6JGSEBKJUJTR2G%2F20221125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221125T111632Z&X-Amz-Expires=1200&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIC%2FmtFgSTa3%2FYQr9bWScAjkl93O%2B9Sj1Oh45CCEOZVP8AiAFdymeLbi2UTK6XGovrHA0pg83VYMRjeO%2B3KovXEyapyqmAwjs%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAEaDDU5Njg4NTU0MTEyMiIM9AnnnVKJd%2FhDAtHeKvoC0rL3yNw%2FY4L7dqt8oYyohGtqtMUSZU4TDYj7xkgWdsJ%2BjVzsW3wsQwQw5zAPSRIV4sl9%2FOND1bbnhv5ehkrxFM5VoDPD19ZEJLE7DsHr5%2FhmwCGc7DlhESj%2BoEQeWpC1pb4reeXXrnnopFIAmR5hNbDkhkSgQGJAisWBmQGr9EZpuDsBdWRhXcdaWaU6OOZf6F2sIArTFcBuKgXI2Xe8s6W6WOF8FO3Lb9HSxgWRcT4fHNQP6msU%2BZJkZSfOC2UiqaLlJmFKiax1KjlivVq6ikLWuExS6PqbJorBs0j8AYl0oG2wYN1MilL581gaATC9eZqWbiKx%2FFnTiVw43WVtjiOxMH52ldcBbFFOAx3JDOkPOmilNN3rcifBWntO2n1W8PJ3FTlRzy9Yz6cPL7k5lCs%2FwY9YKLbZ0qALiedrw7rTz8ieB%2F3JTf8LaSDsNGn6IA%2BCnZT18IKWLH0rSj4hSN6H6stWHVqGa0k5C4G76ZeIrZRlXbRqAvD3MPbCgpwGOp4BvyAvijX4p%2FoiSgdcmuYhyBSuWQi0NBfWezPA4of94Cyp2X2vDy2HU6WdAoo6ByfG%2FttanR05RHqfF7WPEwSo%2FoN3GdYA3rLUD3GMsO5QykhHXYumQLsTGryPbPTSnfxtviEleCDW8J%2FJIZajZVBWDowm4gv0S7YlJC8Z03AjwKD0sh8V3Hh5CX2AUMYI8ksLAzNhioLwSjzfBb6bvls%3D&X-Amz-Signature=7dc1fe45bd6db8e2f2699b2f53248c73df93445b52942cf497c4f99eb47f4ffc
Resolving art-srv-enterprise.s3.amazonaws.com (art-srv-enterprise.s3.amazonaws.com)... 54.231.170.105, 52.217.137.225, 52.217.106.140, ...
Connecting to art-srv-enterprise.s3.amazonaws.com (art-srv-enterprise.s3.amazonaws.com)|54.231.170.105|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 52556789 (50M) [application/x-tar]
Saving to: ‘openshift-client-linux-4.11.11.tar.gz’

openshift-client-linux-4.11.11.tar.gz                               100%[==================================================================================================================================================================>]  50.12M  43.5MB/s    in 1.2s    

2022-11-25 11:16:33 (43.5 MB/s) - ‘openshift-client-linux-4.11.11.tar.gz’ saved [52556789/52556789]
----
+
* You can always find a list of OpenShift clients to download by visiting:
** link:https://access.redhat.com/downloads/content/290[Red Hat products download page^]
** link:https://mirror.openshift.com/pub/openshift-v4/clients/ocp/[OpenShift mirror downloads^]

. Because you will be using this extensively, extract it to a location that will make it easy to use.
+
[source,sh]
----
sudo tar xzf openshift-client-linux-$OCP_RELEASE.tar.gz -C /usr/local/sbin/ oc kubectl
which oc; oc version
----
+
.Sample Output
[source,sh]
----
/usr/local/sbin/oc
Client Version: 4.11.11
Kustomize Version: v4.5.4
----
+
NOTE: This package will provide you both the `oc` client and `kubectl` client, but this course material will use the `oc` client exclusively.

. Set up bash completion for the `oc` client. This will allow you to tab complete many `oc` commands.
+
[source,sh]
----
oc completion bash | sudo tee /etc/bash_completion.d/openshift > /dev/null
. /usr/share/bash-completion/bash_completion
----
+
TIP: You can do the same for other shells, such as `zsh` if you don't have or use `bash` on your local machine.

. Validate your existing Bastion and UtilityVM hosts.
Use the `aws` client to retrieve the current list of your AWS instances.
+
[source,sh]
----
aws ec2 describe-instances
----
+
NOTE: You should see a lot of JSON, representing your two hosts: `bastion` and `utilityvm`. If you do not see any instances that probably means that your lab environment is not in `us-east-2`. That's fine. You will still deploy the cluster to `us-east-2` while your bastion and utility vm remain in another region.

At this point, you are done working on your `bastion`.
You will finish up the configuration later.
In the next section, you will work on the `Utility VM`.

=== Deploy Container Registry

Your utility VM is provided to run services that you need to complete the installation.
OpenShift 4 is deployed with container images.
There are no packages to install.
Think about the things that you might need to host in a disconnected environment as well as things you might want to provide to your cluster once it is built.

This lab will begin to challenge you a little more.
Below are a set of requirements that you need to satisfy.
There are links to documentation that has all of the necessary information to complete this section.

. On your `Utility VM`, follow this lab guide to install a container registry that meets these requirements.
* You will use `podman` to run any containers.
+
TIP: Whenever you see a `docker` command in any of the reference material, you can use `podman` instead.
`Docker` is *_not_* installed in any of your systems.
* Rootless `podman` is already enabled for you, so you do *not* need to be `root` to run your containers.
** See more link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html/managing_containers/finding_running_and_building_containers_with_podman_skopeo_and_buildah#set_up_for_rootless_containers[documentation here^] for reference on how to enable that feature in RHEL 7.7+.
* The container registry will be secured using certificates.
* The registry will be accessible by all other servers in your environment on port 5000.
* You can use a basic container registry that can be pulled from `docker.io/library/registry:2`.
* The registry will use htpassword for authentication
* The registry will offer a user `openshift` with password `redhat`.
* For Reference, you can piece together your own solution here:
** Upstream documentation for deploying this container registry can be found:
** link:https://docs.openshift.com/container-platform/4.11/installing/disconnected_install/installing-mirroring-installation-images.html[Install mirroring images^]
** link:https://docs.docker.com/registry/deploying/[Registry Docs^]

. Now let's start.
From your `bastion`, SSH to `utilityvm`.
An SSH config is provided for you, and `utilityvm` is configured to be short for the FQDN `utilityvm.$GUID.internal`.
Note that this will log you into the `utiltiy VM` as the `ec2-user` user.
That is okay.
+
[source,sh]
----
ssh ec2-user@utilityvm.$GUID.internal
----

. On your `Utility VM`, test `podman` to make sure things are functioning as you expect.
This test will pull the Red Hat Universal Base Image (UBI) and run it as a regular user.
+
[source,sh]
----
podman pull ubi9:9.1.0
podman run ubi9:9.1.0 cat /etc/os-release
----
+
.Sample Output
[source,sh]
----
NAME="Red Hat Enterprise Linux"
VERSION="9.1 (Plow)"
...
----
+
WARNING: Make sure you are logged in as `ec2-user`.
Do not run this as `root`.
+
// Judd & Nate: We're showing this solution because it was a time sink, and not a skill in the competency model
//
// ifeval::[{show_solution} == true]

. Create directories for your data, auth, and certificates that will be used by the container registry.
Because you will use these directories and files in your container, you will need to change permissions as well to run as a regular user.
+
[source,sh]
----
sudo mkdir -p /opt/registry/{auth,certs,data}
sudo chown -R $USER /opt/registry
----

. Because you have a requirement to secure the container registry with certificates, you will create a self-signed certificate.
In a real environment, you would skip this step since you would get your certificate from a legitimate certificate authority.
+
====
WARNING: Please note Openshift 4.11 uses go1.18 which involves deprecating Legacy Common Name certificates in favour of SAN Certificates. If you create a non SAN cert, `oc adm mirror` will fail. 

link:https://access.redhat.com/solutions/4870701[What version of the Kubernetes API is included with each OpenShift 4.x release?^]

link:https://access.redhat.com/solutions/6411021[What Go/Golang version is used in Red Hat OpenShift Container Platform (RHOCP)?^]

link:https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md[Red Hat OpenShift Container Platform 4.11 have Kubernetes 1.24 version (CHANGELOG-1.24.md)^]

*Updating Golang Certificate Libraries*

. First get the required binaries
+
[source,sh]
----
sudo wget --quiet https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssljson_1.5.0_linux_amd64 -O /usr/local/bin/cfssljson

sudo wget --quiet https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssl_1.5.0_linux_amd64 -O /usr/local/bin/cfssl

sudo chmod 755 /usr/local/bin/cfssl /usr/local/bin/cfssljson

cfssl version ; cfssljson --version
----
+
.Sample output
[source,sh]
----
Version: 1.5.0
Runtime: go1.12.12
Version: 1.5.0
Runtime: go1.12.12
----
+
. Define how are we going to create the certificate using ca-config.json, ca-csr.json and server.json files
WARNING: Replace $GUID with your GUID.
+
[source,sh]
----
cd /opt/registry/certs
cat << EOF > ca-config.json
{
  "signing": {
    "default": {
      "expiry": "87600h"
    },
    "profiles": {
      "server": {
        "expiry": "87600h",
        "usages": [
          "signing",
          "key encipherment",
          "server auth"
        ]
      },
      "client": {
        "expiry": "87600h",
        "usages": [
          "signing",
          "key encipherment",
          "client auth"
        ]
      }
    }
  }
}
EOF

cat << EOF > ca-csr.json
{
  "CN": "Red Hat GPTE",
  "hosts": [
    "utilityvm.$GUID.internal"
  ],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "US",
      "ST": "Washington",
      "L": "Seattle",
      "OU": "GPTE"
    }
  ]
}
EOF

cat << EOF > server.json
{
  "CN": "Red Hat GPTE",
  "hosts": [
    "utilityvm.$GUID.internal"
  ],
  "key": {
    "algo": "ecdsa",
    "size": 256
  },
  "names": [
    {
      "C": "US",
      "ST": "Washington",
      "L": "Seattle",
      "OU": "GPTE"
    }
  ]
}
EOF
----

. Then generate the certificate using cfssl
+
[source,sh]
----
cfssl gencert -initca ca-csr.json | cfssljson -bare ca -

cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server.json | cfssljson -bare server
----
+
.Sample Output
[source]
----
$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca -
2020/11/29 14:39:28 [INFO] generating a new CA key and certificate from CSR
2020/11/29 14:39:28 [INFO] generate received request
2020/11/29 14:39:28 [INFO] received CSR
2020/11/29 14:39:28 [INFO] generating key: rsa-2048
2020/11/29 14:39:29 [INFO] encoded CSR
2020/11/29 14:39:29 [INFO] signed certificate with serial number 419787836982310839166614616906469081999179092022

$ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server.json | cfssljson -bare server
2020/11/29 14:43:47 [INFO] generate received request
2020/11/29 14:43:47 [INFO] received CSR
2020/11/29 14:43:47 [INFO] generating key: ecdsa-256
2020/11/29 14:43:47 [INFO] encoded CSR
2020/11/29 14:43:47 [INFO] signed certificate with serial number 171207265842583977941092839695498604824714694201
----
+
* This command will create a CA and also certificates and keys files in the `/opt/registry/certs` directory.
* You can edit the files to make it fit to what you consider better, just keep in mind the host entry **must** be `utilityvm.$GUID.internal`

. Now you can see both ca and server pem files have v3 SAN extension enabled
+
[source,sh]
----
openssl x509 -in ca.pem -text -noout  | grep X509v3 -A 1

openssl x509 -in server.pem -text -noout  | grep X509v3 -A 1
----
+
.Sample Output
[source,texinfo]
----
openssl x509 -in ca.pem -text -noout  | grep X509v3 -A 1
        X509v3 extensions:
            X509v3 Key Usage: critical
                Certificate Sign, CRL Sign
            X509v3 Basic Constraints: critical
                CA:TRUE
            X509v3 Subject Key Identifier:
                C4:01:54:11:75:F3:0B:C5:27:5C:8E:5E:E4:2C:4C:5F:5D:46:E8:FD

openssl x509 -in server.pem -text -noout  | grep X509v3 -A 1
        X509v3 extensions:
            X509v3 Key Usage: critical
                Digital Signature, Key Encipherment
            X509v3 Extended Key Usage:
                TLS Web Server Authentication
            X509v3 Basic Constraints: critical
                CA:FALSE
            X509v3 Subject Key Identifier:
                68:66:20:BB:A9:18:56:14:B9:FB:E1:18:C2:4D:06:32:B3:87:CD:CA
            X509v3 Subject Alternative Name:
                DNS:utilityvm.$GUID.internal
----
+
* Check that the DNS line is equal to 'DNS:utilityvm.$GUID.internal' under the X509v3 extensions section, this is indicative of a valid SAN certificate.
====

. Switch back to your $HOME directory.
+
[source,sh]
----
cd $HOME
----

. Since this registry will be secured, create a username and password.
You are using `htpasswd` as the authentication mechanism, so you will need to add these to a file that will be mounted into the container registry.
+
[source,sh]
----
htpasswd -bBc /opt/registry/auth/htpasswd openshift redhat
----
+
* This will create a user named `openshift` with a password of `redhat`

. At this point, all of the requirements necessary to start your container registry shoudl be satisfied.
You will now use rootless `podman` to start the container.
+
[source,sh]
----
podman run -d --name mirror-registry \
    -p 5000:5000 --restart=always \
    -v /opt/registry/data:/var/lib/registry:z \
    -v /opt/registry/auth:/auth:z \
    -e "REGISTRY_AUTH=htpasswd" \
    -e "REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm" \
    -e "REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd" \
    -v /opt/registry/certs:/certs:z \
    -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/server.pem \
    -e REGISTRY_HTTP_TLS_KEY=/certs/server-key.pem \
    docker.io/library/registry:2
----
+
* The container registry starts with the following options:
** It is listening on port 5000
** It has `htpasswd` authentication configured and is using the file you created
** It is using the certificates you created

. Test your connection to the registry.
+
[source,sh]
----
curl -u openshift:redhat -k https://utilityvm.$GUID.internal:5000/v2/_catalog
----
+
.Sample Output
[source,sh]
----
{"repositories":[]}
----

. Test your connection without bypassing the TLS check.
+
[source,sh]
----
curl -u openshift:redhat https://utilityvm.$GUID.internal:5000/v2/_catalog
----
+
.Sample Output
[source]
----
curl: (60) SSL certificate problem: unable to get local issuer certificate
More details here: https://curl.haxx.se/docs/sslcerts.html

curl failed to verify the legitimacy of the server and therefore could not
establish a secure connection to it. To learn more about this situation and
how to fix it, please visit the web page mentioned above.
----
+
* The first test that ignores the self-signed certificates completes successfully
* The second test that does not ignore the self-signed certificates fails

. Since your container registry is secured and OpenShift will not tolerate untrusted certificates, you must add the certificates to your trusted store.
+
[source,sh]
----
sudo cp /opt/registry/certs/ca.pem /etc/pki/ca-trust/source/anchors

sudo update-ca-trust extract

curl -u openshift:redhat https://utilityvm.$GUID.internal:5000/v2/_catalog
----
+

.Sample Output
[source,sh]
----
{"repositories":[]}
----
// endif::[]

. Test to ensure you can push and pull an image from the container registry.
+
[source,sh]
----
podman pull ubi9:9.1.0

podman login -u openshift -p redhat utilityvm.$GUID.internal:5000

podman tag registry.access.redhat.com/ubi9:9.1.0 utilityvm.$GUID.internal:5000/ubi9:9.1.0

podman push --remove-signatures utilityvm.$GUID.internal:5000/ubi9:9.1.0
----
+
.Sample Output
[source]
----
Copying blob c6e4113dc4f5 done  
Copying config 0ed7d97dff done  
Writing manifest to image destination
Storing signatures
----
+
* In the tests above, you did the following:
** Pull a UBI image from Red Hat to the container registry running on your `Utility VM`.
If you previously pulled this image, it is already available and will not be pulled again.
** Logged into the container registry you deployed on your `Utility VM`.
** Tagged an image to prepare it to be pushed to the new container registry.
** Pushed the container image to the new container registry.

. Verify that the image you pushed is being written to the correct location in the file system of your `Utility VM`.
You should see a single folder named `ubi9`.
+
[source,sh]
----
ls /opt/registry/data/docker/registry/v2/repositories
----

. Log off of the `Utility VM` to the `bastion`, where you will continue in the next section (type `exit` or `Ctrl-D`).

You now have a container registry running in your lab environment.
This is a very basic example of a container registry without much advanced functionality, but it serves a purpose to help get what matters deployed - OpenShift.
Typically you will be working with an existing enterprise container registry or service that you will simply need credentials to in order to proceed with the next section.
Examples of this might be Quay Enterprise, Quay.io, Artifactory, Nexus, ECR, GCR, and many more.

In the next section, you will build on this as you move forward with your disconnected installation of OpenShift 4.

=== Mirror Content

[CAUTION]
You are finished with the UtilityVM. All future steps will be executed on the *Bastion* VM!

Now that you have a container registry set up, secured, and accessible within your environment, you will need to get the content mirrored into your local environment.
What do you need in order to install OpenShift 4?
Remember, OpenShift 4 is deployed with all components running as containers and controlled by Operators.
In OpenShift 3, you had to come up with a list of container images and tags and pull them into your local environment before you could run the installer.
The process was tedious and error prone.
In OpenShift 4, all of the container images and versions are delivered as part of the payload, so there is no guessing on exact container images or versions you need.

The `oc` client provides an easy way for you to get all of the required images.
Using the `oc adm release` command, you can see information about releases, inspect the content of the release, and mirror release content across image registries.
This means that rather than using several different tools, you will be able to pull all of the containers you need for an OpenShift 4 install in a single command.
The `oc adm release mirror` command will copy the images and update payload for a given release from one registry to another.
In this case, it will copy from `quay.io` to the local container registry you deployed in the previous section.
By default this command will not alter the payload and will print out the configuration that must be applied to a cluster to use the mirror.
There is, however, a little bit of prep work to complete first.

. Exit your utility VM and on your `*bastion*` start by testing your connection to the container registry you installed on your `Utility VM`.
Remember that you secured this container registry with a certificate that you generated on the `Utility VM`.
You should see a single repository, which you created in your test at the end of the last section.
+
[source,sh]
----
curl -u openshift:redhat https://utilityvm.$GUID.internal:5000/v2/_catalog
----
+
.Sample Output
[source]
----
curl: (60) SSL certificate problem: unable to get local issuer certificate
More details here: https://curl.haxx.se/docs/sslcerts.html

curl failed to verify the legitimacy of the server and therefore could not
establish a secure connection to it. To learn more about this situation and
how to fix it, please visit the web page mentioned above.
----

. You haven't added the new self-signed certificate to your trusted store on the `bastion`.
Do this and test again.
+
[source,sh]
----
sudo scp utilityvm.$GUID.internal:/opt/registry/certs/ca.pem /etc/pki/ca-trust/source/anchors

sudo update-ca-trust

curl -u openshift:redhat https://utilityvm.$GUID.internal:5000/v2/_catalog
----
+
.Sample Output
[source,sh]
----
{"repositories":["ubi9"]}
----

. [[pullsecret]]You can now connect to your local container registry.
Proceed by mirroring all of the content necessary to install OpenShift 4.
+
ifeval::[{show_solution} == true]
NOTE: Create your own solution for the following steps.

endif::[]
.. On your *Bastion*:
.. Create a pull secret for your new container registry running on your Utility VM
.. Create a file with your OpenShift pull secret
* You can get an OpenShift pull secret from link:https://cloud.redhat.com/openshift/install/aws/installer-provisioned[cloud.redhat.com^]
** Use the same Red Hat account you use to log into the customer portal for downloads, knowledge base, etc.
** If you do not have an account, create a link:https://developers.redhat.com/[Red Hat Developer account^]
.. Merge your pull secrets into a single `json` file that you will use for both mirroring and installing
.. Mirror the content to your local container registry
* You can find instructions for mirroring the content in the link:https://docs.openshift.com/container-platform/4.11/installing/installing_aws/installing-aws-network-customizations.html#installation-configuration-parameters-optional_installing-aws-network-customizations[OpenShift Docs^]
+
NOTE: Make sure you save the `imageContentSource` and `ImageContentSourcePolicy` output from the mirroring so you will know what to use in later steps.
+
WARNING: When running the `oc adm release mirror` command, as of the OpenShift 4.11, the release must also include the system architecture (i.e. x86_64).

ifeval::[{show_solution} == true]
. Create a pull secret that can be used to push content into the container registry you installed on the `Utility VM`.
+
[source,sh]
----
podman login -u openshift -p redhat --authfile $HOME/pullsecret_config.json utilityvm.$GUID.internal:5000
----

. Look at the `json` file you created in the previous command.
This file now includes the container registry hostname as well as an authentication token based on the credentials you provided in the `podman` command.
+
[source,sh]
----
cat $HOME/pullsecret_config.json
----
+
.Sample Output
[source]
----
{
	"auths": {
		"utilityvm.$GUID.internal:5000": {
			"auth": "b3BlbnNoaWZ0OnJlZGhhdA=="
		}
	}
----
+
. That is one of the credentials you need.
The other is the OpenShift pull secret that you got from Red Hat.
Create a file called `$HOME/ocp_pullsecret.json`.
Example (the information is incomple in this example):
+
[source]
----
cat $HOME/ocp_pullsecret.json
----
+
.Sample Output
[source,texinfo]
----
{"auths":{"cloud.openshift.com":{"auth":"b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K3drdWxoYW5lcmVkaGF0Y29tMWZydXhtMWRzbnNvcHJmcHFnMTd2cnF1emt2OjhXSlhNM1lINjNDTkRUMDY0MVBZVUlIQkxONVZTUUpTMFJIM1U5WEhKWjRLNDdRTjZMMUVFNDVBUDk0RU0wRUo=","email":"<your e-mail address>"},"quay.io":{"auth":"b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K3drdWxoYW5lcmVkaGF0Y29tMWZydXhtMWRzbnNvcHJmcHFnMTd2cnF1emt2OjhXSlhNM1lINjNDTkRUMDY0MVBZVUlIQkxONVZTUUpTMFJIM1U5WEhKWjRLNDdRTjZMMUVFNDVBUDk0RU0wRUo=","email":"<account>@redhat.com"},"registry.connect.redhat.com":{"auth":"NTA0ODY1Mzd8dWhjLTFGUlV4TTFEU25zT3ByZlBxZzE3VlJRdXprVjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXdZbVZtTm1Jek1UWm1aV0kwWXpWaU9UWTNNemczTjJRMk9ERXpaRFV4T0NKOS5aS2Q2SEpTRDQ5dUE1R1VWLTBETjl4SldNQnJqczhYN1RUT2VPaDROTTZGWllVblJ2RnotYTBFOW9SR21hbTllT0RlaVplX3pyc2dWZkFkT1hTX0QxQ0pyaERDOUFfa3FoZ1dmOFBCd0JrWTNCWk9zZFBJWkdNdW1CNC00aUZCelM5V2lndnzz4d2DFDMkkpsZHVNSzdfeWE5aUQzTWV0d29ZLUt1c1VJc1U4d3lqOU9ueUFibEJTNFliRGZmVjY2QktsNTBCa19RTFgzLWxIaGNRbU5SX1B4RW1PRUJYU3U3S3pQQzhvaG1kb3Mtb0c4OGxjNjdqSG9WMmhCcENUN0NmZFZPLUp4eUQwMUM5ZHZabW1ZNktJd1ZQbnJ1eDJVLTUtdENFSVpsbE5LMXZkeG05RTdzWHhtS1A1MHFsSmxBRnhVTjFjYWxOVF9jMkJHMWxxby14b2J0OHFmZTQ1RWNYeEROZWpVSjJwdG9VLVBtVGV6SnZkNUFCcjBnMVFIZTNJRjNKczhHLWNfVG90OVlFcWQ2Ui1tMzZieE9KamM5cGtYczQ1TENYRlkwMU5VUmlRNk82ZDZwUmNnRGxfMTNDkc05yR2ltMTNSVXVQN0t4Zjh4Q1dXTUZIUGlQbmJKdXdpd1k0d3hNdnNSTDNlamFSdGxKQl9yODB5RXRxTWNoRmZpV2xBNGZjMmI5VGdEYkdaSmdCcUtCa0JkT2t2VWZQMzB2cm9oeF9FbVAwUTJIbElndDEtZ01GaTJHZjd3dlE5ZHhtZzhtTzZWUFBFaWxhQk5hY0hMcU9QWE9LalVWR1prRnpyenZZMU83XzlIN2R2YXZwVXVHVmZxTmx3QXJVZndjNklpQUZRak02S2RFQnNMeTQwSDdkZG95S0J6V29XNU96NkxsRQ==","email":"<account>@redhat.com"},"registry.redhat.io":{"auth":"NTA0ODY1Mzd8dWhjLTFGUlV4TTFEU25zT3ByZlBxZzE3VlJRdXprVjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXdZbVZtTm1Jek1UWm1aV0kwWXpWaU9UWTNNemczTjJRMk9ERXpaRFV4T0NKOS5aS2Q2SEpTRDQ5dUE1R1VWLTBETjl4SldNQnJqczhYN1RUT2VPaDROTTZGWllVblJ2RnotYTBFOW9SR21hbTllT0RlaVplX3pyc2dWZkFkT1hTX0QxQ0pyaERDOUFfa3FoZ1dmOFBCd0JrWTNCWk9zZFBJWkdNdW1CNC00aUZCelM5VDMk1UYkpsZHVNSzdfeWE5aUQzTWV0d29ZLUt1c1VJc1U4d3lqOU9ueUFibEJTNFliRGZmVjY2QktsNTBCa19RTFgzLWxIaGNRbU5SX1B4RW1PRUJYU3U3S3pQQzhvaG1kb3Mc4OGxfwvawejNjdqSG9WMmhCcENUN0NmZFZPLUp4eUQwMUM5ZHZabW1ZNktJd1ZQbnJ1eDJVLTUtdENFSVpsbE5LMXZkeG05RTdzWHhtS1A1MHFsSmxBRnhVTjFjYWxOVF9jMkJHMWxxby14sdfdfb2J0OHFmZTQ1RWNYeEROZWpVSjJwdG9VLVBtVGV6SnZkNUFCcjBnMVFIZTNJRjNKczhHLWNfVG90OVlFcWQ2Ui1tMzZieE9KamM5cGtYczQ1TENYRlkwMU5VUmlRNk82ZDZwUmNnRGxfMTNDxexg3DDZ305yR2ltMTNSVXVQN0t4Zjh4Q1dXTUZIUGlQbmJKdXdpd1k0d3hNdnNSTDNlamFSdGxKQl9yODB5RXRxTWNoRmZpV2xBNGZjMmI5VGdEYkdaSmdCcUtCa0JkT2t2VWZQ2cm9oeF9FbVAwUTJIbElndDEtZ01GaTJHZjd3dlE5ZHhtZzhtTzZWUFBFaWxhQk5hY0hMcU9QWE9LalVWR1prRnpyenZZMU83XzlIN2R2YXZwVXVHVmZxTmx3QXJVZndjNklpQUZRak02S2RFQnNMeTQwSDdkZG95S0J6V29XNU96NkxsRQ==","email":"<account>@redhat.com"}}}
----
+
NOTE: The example above is not a valid pull secret. You should have in your own file credentials for quay.io, registry.redhat.io and cloud.openshift.com.
+
. You can only use one pull secret when mirroring the images to your local container registry as well as when you install OpenShift, so you need to merge the pull secrets you created in the previous two steps into a single `json` file named `merged_pullsecret.json`.
Remember that you created your pullsecret_config.json in step 4.
+
[source,sh]
----
jq -c --argjson var "$(jq .auths $HOME/pullsecret_config.json)" '.auths += $var' $HOME/ocp_pullsecret.json > merged_pullsecret.json

jq . merged_pullsecret.json
----
+
.Sample Output
[source,json]
----
{
  "auths": {
    "cloud.openshift.com": {
      "auth": "c2UtZGV2K25zdGVwaGFuMWRma210U2M2VuYTZxZ2R4bHJwOklJaVkVXMUJDVTFESVBTN0hISjhRR1E5UDI5WEFJNEVQSUw2TjNQN0o0R1ZaQVRYR0U=",
      "email": "<your-email>"
    },
    "quay.io": {
      "auth": "GV2K25zdGVwaGFuMWRma210bHJwdU2M2VuYTZxZ2R4bFHSlJaVkVXMUJDVTFESVBTN0hISjhRR1E5UDI5WEFJNEVQSUw2TjNQN0o0R1ZaQVRYR0U=",
      "email": "<your-email>"
    },
    "registry.connect.redhat.com": {
      "auth": "NaUo5LmV5SnpkV0lpT2lKall6VmtZelJqWVRNd05UZzBZelkyWWpFeVkyTTVNMlUxWVRNNU0yRm1aU0o5LkFnWW00SjB5R1d4OHZ4bDNhcnVJSlFrTEFHb2NiVEQ4dkRNNUdIdEZpQU4zOGp4bXkyMlJLX004MGN2alZBa3FUWjJobEJqQ25kMGNEdlTUx6TmozSjNKVmxZWm9VMVR0OXNxa25vYWxWdTJEZ0xDalVPeHlOUVFTd0NuMTN3WFoxTl9DWnNXekxhU0tFZzc0VzUtR1YzTGVHZU92RV9EdTlld3RjVROXBfUXBZYzR0elpKczlrUHFlakVnNC1xOU0tVjBqajY4NGd3dk90TGYzcmV1VjJBLTFuS2ltRXNnVGhlbHloVllzSENaWVFveHNkNmFjZnVMMnhSa01KMXAyeVJBREhoNXJhUG51Nnh0Qjk1VmdhTVl4dkVURk43X2ctXzVqTWFGSnF6Ynk5Q2JxaHFRT1VNZnFFNHQzclltUGVIMkp0MTRMVWVkRHlDbzJXWUhzMlRjeGNYbUd1VFhmR2xvdmlYeXV0MDBfRndXM1N0MDhHLVlJX1htYXpWclRuVV92QVl2Tm5waWNPMzZVYUxoUXp2dUJ2ZnQtQUc5eEY1dDIwakZrZTNHZDhiNWxTN0tSUVRsRHNnQmRqbmkxQnZNYUJad2NQWEVieFd6dFJYNmdndXR1Z1lNNnJfc3E2ODJOZlRoeUdjLTE2RkZBNjdwWExWS0JyY1BlZzY4RWd6QV9HdC16MzlCWktSVTRwVnowbjRpX085WlV3MGlvbDlKVGJQcU5mZ1JRYWNUaEZzeHJWd3E3aVB4Zk5ZZWV0aC1zVWI5UWpPTDN2amNzV05qdGRGU2huSWVwTFVMOUlsWjB2YUR5clBB",
      "email": "<your-email>"
    },
    "registry.redhat.io": {
      "auth": "4OHZ4bDNhcnVJSlFrTEFHb2NiVEQ4dkRNNUdIdEZpQU4zOGp4bXkyMlJLX004MGN2alZBa3FUWjJobEJqQ25kMGNYTVhxaXNFSlBxdzJOT3dlU0o1TGZxMEdlTUx6TmozSjNKVmxZWm9VMVR0OXNxa25vYWxWdTJEZ0xDalVPeHlOUVFTd0NuMTN3WFoxTl9TGVHZU92RV9EdTlld3NBMWt5MkYyMi01NlVES2w2Nmc4cU5waWlDRjVROXBfUXBZYzR0elpKczlrUHFlakVnNC1xOU0tVjBqajY4NGd3dk90TGYzcmV1VjJBLTFuS2ltRXNnVGhlbHloVllzSENaWVFveHNkNmFjZnVMMnhSa01KMXAyeVJBREhoNXJhUG51Nnh0Qjk1VmdhTVl4dkVURk43X2ctXzVqTWFGSnF6Ynk5Q2JxaHFRT1VNZnFFNHQzcllRjeGNYbUd1VFhmR2xvdmlYeXV0MDBfRndXM1N0MDhHLVlJX1htYXpWclRuVV92QVl2Tm5waWNPMzZVYUxoUXp2dUJ2ZnQtQUc5eEY1dDIwakZrZTNHZDhiNWxTN0tSUVRsRHNnQmRqbmkxQnZNYUJad2NQWEVieFd6dFJYNmdndXR1Z1lNNnJfc3E2ODJOZlRoeUdjLTE2RkZBNjdwWExWS0JyY1BlZzY4RWd6QV9HdC16MzlCWktSVTRwVnowbjRpX085WlV3MGlvbDlKVGJQcU5mZ1JRYWNUaEZzeHJWd3EG4xYjNpQzZDbnV0aC1zVWI5UWpPTDN2amNzV05qdGRGU2huSWVwTFVMOUlsWjB2YUR5clBB",
      "email": "<your-email>"
    },
    "utilityvm.$GUID.internal:5000": {
      "auth": "b3BlbnNoaWZ0OnJlZGhhdA=="
    }
  }
}
----
+
* This file is a combination of the `auths` from your OpenShift pull secret and your local container registry pull secret.
+
WARNING: The output above is a *sample*.
Yours should be different.
If you try to use this, you will fail.

. Set the following environment variables.
This is not a required step to mirror content, but it will make subsequent command easier.
Most of these are self-explanatory, but some additional details are included after the commands below.
+
[source,sh]
----
ansible localhost -m lineinfile -a "path=$HOME/.bashrc regexp='^export LOCAL_REGISTRY' line='export LOCAL_REGISTRY=utilityvm.$GUID.internal:5000'"

ansible localhost -m lineinfile -a 'path=$HOME/.bashrc regexp="^export LOCAL_REPOSITORY" line="export LOCAL_REPOSITORY=ocp4/openshift4"'

ansible localhost -m lineinfile -a 'path=$HOME/.bashrc regexp="^export LOCAL_SECRET_JSON" line="export LOCAL_SECRET_JSON=$HOME/merged_pullsecret.json"'

ansible localhost -m lineinfile -a 'path=$HOME/.bashrc regexp="^export PRODUCT_REPO" line="export PRODUCT_REPO=openshift-release-dev"'

ansible localhost -m lineinfile -a 'path=$HOME/.bashrc regexp="^export RELEASE_NAME" line="export RELEASE_NAME=ocp-release"'

ansible localhost -m lineinfile -a 'path=$HOME/.bashrc regexp="^export ARCHITECTURE" line="export ARCHITECTURE=x86_64"'

source $HOME/.bashrc
----
+
* `LOCAL_REGISTRY` is the container registry you installed on your `Utility VM`.
If you were doing this in another environment, it would be the container registry that you want to mirror the container images *to*.
* `LOCAL_REPOSITORY` is the repository and image name that you want to push the images to.
You should choose something descriptive here, but the choice is yours.
* `LOCAL_SECRET_JSON` is the merged pull secret you created.
This pull secret containers credentials to pull the OpenShift images and push them to your local container registry.
This must be set to the *absolute path*.
* `PRODUCT_REPO` is the repository you are mirroring the images *from*.
Do not change this.
* `RELEASE_NAME` refers to the images your will be pulling.
Do not change this.
* `ARCHITECTURE` is the architecture of the server, such as x86_64.
Do not change this.
+
WARNING: Do not forget to source your `.bashrc` file in the section above.
If you do not, none of the environment variables will be available and you will fail on subsequent steps.

. All of your pre-requisites are finally complete and you are ready to mirror the OpenShift 4 content to your local container registry!
As discussed earlier, the process in OpenShift 4 is much easier than it used to be.
The following command will do everything necessary.
Run this on your `bastion`.
+
[source,sh]
----
oc adm -a ${LOCAL_SECRET_JSON} release mirror \
   --from=quay.io/${PRODUCT_REPO}/${RELEASE_NAME}:${OCP_RELEASE}-${ARCHITECTURE} \
   --to=${LOCAL_REGISTRY}/${LOCAL_REPOSITORY} \
   --to-release-image=${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}:${OCP_RELEASE}-${ARCHITECTURE}
----

. If your command runs successfully, you should have output similar to this.
There is a lot happening here, but it basically comes down to letting OpenShift decide what images it needs rather than you providing a static (and usually outdated) list.
All of the required images are pulled from `quay.io` and pushed to your container registry running on `utilityvm.$GUID.internal`.
+
.Sample Output
[source,sh,options="nowrap"]
----
info: Mirroring 172 images to utilityvm.$GUID.internal:5000/ocp4/openshift4 ...
utilityvm.$GUID.internal:5000/
  ocp4/openshift4
    blobs:
      quay.io/openshift-release-dev/ocp-release sha256:d8190195889efb5333eeec18af9b6c82313edd4db62989bd3a357caca4f13f0e 1.404KiB
      quay.io/openshift-release-dev/ocp-release sha256:733678a2b009a0e3c6a7c9ceae4fe1edc97f6155879e1af6dde4be97d4a476d3 1.68KiB
      quay.io/openshift-release-dev/ocp-release sha256:54cd7ee39c83d12d117b744e8024b260aa499973fc0a42305df90008cc6dc5b7 857.6KiB
      quay.io/openshift-release-dev/ocp-release sha256:8ec95a25d51ea58de5addd20a249315ce41a6c6ffc27bebe3e9f47969efa0526 7.046MiB
      quay.io/openshift-release-dev/ocp-release sha256:4a3e68d559e3ab413adc706111756c4c65b6dc191e2ea2f67b1ecb0d3b36456a 11.32MiB
      quay.io/openshift-release-dev/ocp-release sha256:adf3b07f663f02359b29366f58437d1329c35ab2480bfe2a134eded85f5d4cf2 25.12MiB
      quay.io/openshift-release-dev/ocp-release sha256:97da74cc6d8fa5d1634eb1760fd1da5c6048619c264c23e62d75f3bf6b8ef5c4 75.84MiB
    blobs:
      quay.io/openshift-release-dev/ocp-v4.0-art-dev sha256:d8190195889efb5333eeec18af9b6c82313edd4db62989bd3a357caca4f13f0e 1.404KiB
      quay.io/openshift-release-dev/ocp-v4.0-art-dev sha256:c9246b8401debaae1a53523aaf24396c92bbd35c3fc2c35d5cb222de346d2c79 1.816KiB
      quay.io/openshift-release-dev/ocp-v4.0-art-dev sha256:c9e43630920245875e861c15ad5c8d29ae114fa383f707eb8a30804839ffb627 2.05KiB
      quay.io/openshift-release-dev/ocp-v4.0-art-dev sha256:4c796ba9bb3644a871862d28f9993f65ec731599e1452cd75ee30e2a54bcd819 3.173KiB
      quay.io/openshift-release-dev/ocp-v4.0-art-dev sha256:f5b7a002f7b3d22d9101d4690c50217384ec9653910ee058beebc9df2aaec140 4.892KiB
  [...]
  (output abridged)

    manifests:
      sha256:02f350419b8e9298af62810a5e4bae74ce342c163ad036c33cbd8cf934fcd7f2 -> 4.11.11-x86_64-nutanix-machine-controllers
      sha256:034895ee76beb49750d0554b1970bd8db4601d0e178bc753cc0087f4610e46e2 -> 4.11.11-x86_64-prometheus-operator
      sha256:03b7419793b1887e5ccac05d2a79a50f43d160b61ec5629d86bcfd1d7a6ac4f5 -> 4.11.11-x86_64-kuryr-cni
      sha256:03de8321d9fb1c041c6f9ccc65be43c7703ed5881ef62758beb2b7737e90ea76 -> 4.11.11-x86_64-ironic
      sha256:04147e72e1e8886b27e36d27c0d2110cf64043f18933d170d02a33ecedd8948c -> 4.11.11-x86_64-tests
      sha256:0456ff444ee8f8d742ae2f562155ba18b973bed4d15d4b57999515eca3101933 -> 4.11.11-x86_64-configmap-reloader
  [...]
  (output abridged)

  stats: shared=5 unique=346 size=13.61GiB ratio=0.99

phase 0:
  utilityvm.$GUID.internal:5000 ocp4/openshift4 blobs=351 mounts=0 manifests=172 shared=5

info: Planning completed in 22.92s
uploading: utilityvm.$GUID.internal:5000/ocp4/openshift4 sha256:b536e22759029776a5bd3059d33c13bf8a69c7bee646027065aea9f6baaad24d 10.49MiB
uploading: utilityvm.$GUID.internal:5000/ocp4/openshift4 sha256:c090aa4d4badcacf77a5f833a3cc29afc0e579fc9770e65676fc853c20ba795d 419.3KiB
uploading: utilityvm.$GUID.internal:5000/ocp4/openshift4 sha256:ec1681b6a383e4ecedbeddd5abc596f3de835aed6db39a735f62395c8edbff30 70.44MiB
  [...]
  (output abridged)

sha256:247d2c8dfd4fceeaad2eeaea038c9dc707ef6e0263972fc9c0918c42c25852b6 utilityvm.$GUID.internal:5000/ocp4/openshift4:4.11.11-csi-external-resizer
sha256:b9ba145f99aceb1b9b78b5b588adf641c94f249b2553c5253f0cc034eaa7cf66 utilityvm.$GUID.internal:5000/ocp4/openshift4:4.11.11-coredns
sha256:f215c15aea3116be10c30e62b6ae4f2fe9f3d6b89655bcd7734f40eb719cbb8f utilityvm.$GUID.internal:5000/ocp4/openshift4:4.11.11-operator-lifecycle-manager
sha256:d9412a4249e713f68c4359e5545d64cc6d17b19643fbfe61db4050cc9dd64efc utilityvm.$GUID.internal:5000/ocp4/openshift4:4.11.11-aws-pod-identity-webhook
sha256:fcf480b686c1c8d3b9612fb48f5e2b7239a03734f7f3bf9d5bf90b98d7bf62c8 utilityvm.$GUID.internal:5000/ocp4/openshift4:4.11.11-cluster-kube-apiserver-operator
  [...]
  (output abridged)

info: Mirroring completed in 3m24.63s (71.9MB/s)

Success
Update image:  utilityvm.$GUID.internal:5000/ocp4/openshift4:4.11.11-x86_64
Mirror prefix: utilityvm.$GUID.internal:5000/ocp4/openshift4
Mirror prefix: utilityvm.$GUID.internal:5000/ocp4/openshift4:4.11.11-x86_64

To use the new mirrored repository to install, add the following section to the install-config.yaml:

imageContentSources:
- mirrors:
  - utilityvm.$GUID.internal:5000/ocp4/openshift4
  source: quay.io/openshift-release-dev/ocp-release
- mirrors:
  - utilityvm.$GUID.internal:5000/ocp4/openshift4
  source: quay.io/openshift-release-dev/ocp-v4.0-art-dev


To use the new mirrored repository for upgrades, use the following to create an ImageContentSourcePolicy:

apiVersion: operator.openshift.io/v1alpha1
kind: ImageContentSourcePolicy
metadata:
  name: example
spec:
  repositoryDigestMirrors:
  - mirrors:
    - utilityvm.$GUID.internal:5000/ocp4/openshift4
    source: quay.io/openshift-release-dev/ocp-release
  - mirrors:
    - utilityvm.$GUID.internal:5000/ocp4/openshift4
    source: quay.io/openshift-release-dev/ocp-v4.0-art-dev

----
+
* As of the 4.11.11 release, there are approximately 172 images that are mirrored into your local container registry.
* *Make note of the output*.
You will need to use the `imageContentSources` in the next section.
endif::[]
+
. To verify that all the images are indeed available in your container registry, try pulling one.
Note that you'll have to provide your `authfile` since you are not logged in to the container registry with `podman`.
+
[source,sh]
----
podman pull --authfile $HOME/pullsecret_config.json utilityvm.$GUID.internal:5000/ocp4/openshift4:$OCP_RELEASE-$ARCHITECTURE-operator-lifecycle-manager
----
+
.Sample Output
[source,sh,options="nowrap"]
----
Trying to pull utilityvm.smp1235.internal:5000/ocp4/openshift4:4.11.11-x86_64-operator-lifecycle-manager...
Getting image source signatures
Copying blob 97da74cc6d8f skipped: already exists  
Copying blob d8190195889e skipped: already exists  
Copying blob 8ec95a25d51e skipped: already exists  
Copying blob 4ff1f7ea8437 done  
Copying blob 4a3e68d559e3 skipped: already exists  
Copying config c1350b8664 done  
Writing manifest to image destination
Storing signatures
c1350b866488093a04ba0833c53135bc111162cc9eb1a9782351be0d77bee5d0
----

. Make sure the new image shows up in your local image storage on the `bastion`.
+
[source,sh]
----
podman images
----
+
.Sample Output
[source,sh,options="nowrap"]
----
REPOSITORY                                       TAG                                        IMAGE ID      CREATED      SIZE
utilityvm.smp1235.internal:5000/ocp4/openshift4  4.11.11-x86_64-operator-lifecycle-manager  c1350b866488  5 weeks ago  644 MB
----

. Take a minute to verify the version information you have downloaded.
Again, you can use the `oc adm release` command.
+
[source,sh]
----
oc adm release info -a ${LOCAL_SECRET_JSON} "${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}:${OCP_RELEASE}-${ARCHITECTURE}" | head -n 18
----
+
.Sample Output
[source,sh,options="nowrap"]
----
Name:           4.11.11
Digest:         sha256:eb84d8fa95d323a20ce80a518cfd2cc87da5b8f0c89204874f73ee05e24344d9
Created:        2022-10-26T09:29:46Z
OS/Arch:        linux/amd64
Manifests:      594
Metadata files: 1

Pull From: utilityvm.smp1235.internal:5000/ocp4/openshift4@sha256:eb84d8fa95d323a20ce80a518cfd2cc87da5b8f0c89204874f73ee05e24344d9

Release Metadata:
  Version:  4.11.11
  Upgrades: 4.10.16, 4.10.17, 4.10.18, 4.10.20, 4.10.21, 4.10.22, 4.10.23, 4.10.24, 4.10.25, 4.10.26, 4.10.27, 4.10.28, 4.10.29, 4.10.30, 4.10.31, 4.10.32, 4.10.33, 4.10.34, 4.10.35, 4.10.36, 4.10.37, 4.10.38, 4.10.39, 4.11.0, 4.11.1, 4.11.2, 4.11.3, 4.11.4, 4.11.5, 4.11.6, 4.11.7, 4.11.8, 4.11.9, 4.11.10
  Metadata:
    url: https://access.redhat.com/errata/RHSA-2022:7201

Component Versions:
  kubernetes 1.24.6                
  machine-os 411.86.202210201510-0 Red Hat Enterprise Linux CoreOS
----

. You can compare this information with what you would get from doing a connected install.
Run the same command, but point it to the Red Hat repositories hosted on `quay.io`.
Except for the "Pull From" line, this should look identical to your output above.
+
[source,sh]
----
oc adm release info -a ${LOCAL_SECRET_JSON} "quay.io/${PRODUCT_REPO}/${RELEASE_NAME}:${OCP_RELEASE}-${ARCHITECTURE}" | head -n 18
----
+
.Sample Output
[source,sh,options="nowrap"]
----
Name:           4.11.11
Digest:         sha256:eb84d8fa95d323a20ce80a518cfd2cc87da5b8f0c89204874f73ee05e24344d9
Created:        2022-10-26T09:29:46Z
OS/Arch:        linux/amd64
Manifests:      594
Metadata files: 1

Pull From: quay.io/openshift-release-dev/ocp-release@sha256:eb84d8fa95d323a20ce80a518cfd2cc87da5b8f0c89204874f73ee05e24344d9

Release Metadata:
  Version:  4.11.11
  Upgrades: 4.10.16, 4.10.17, 4.10.18, 4.10.20, 4.10.21, 4.10.22, 4.10.23, 4.10.24, 4.10.25, 4.10.26, 4.10.27, 4.10.28, 4.10.29, 4.10.30, 4.10.31, 4.10.32, 4.10.33, 4.10.34, 4.10.35, 4.10.36, 4.10.37, 4.10.38, 4.10.39, 4.11.0, 4.11.1, 4.11.2, 4.11.3, 4.11.4, 4.11.5, 4.11.6, 4.11.7, 4.11.8, 4.11.9, 4.11.10
  Metadata:
    url: https://access.redhat.com/errata/RHSA-2022:7201

Component Versions:
  kubernetes 1.24.6                
  machine-os 411.86.202210201510-0 Red Hat Enterprise Linux CoreOS
----

You now have all of the container images necessary to install an OpenShift 4 cluster in a disconnected environment.
You didn't have to look up a list or write a script or do anything other than know what version of OpenShift 4 you wanted to install, gather a few pieces of data from the documentation, and run a simple command.
In addition to the images, you also have the `imageContentSources` data you will need to provide to the installer so that it knows where to pull the images from.

=== Prepare Installation Artifacts

The OpenShift installer can do a full cluster install and deploy an opinionated cluster using the IPI method.
To do this, you run a simple command - `openshift-install create cluster`.
With simple comes lack of options, though.
Since you need to point your installer to use your mirrored images, you must perform this installation using the UPI method.
There are several phases of the `openshift-install` tool that you will have to work through.

Before you get started on creating all of the installation artifacts required, you are missing a key piece - the `openshift-install` binary!
If you were doing a connected install, you would want to visit the link:https://mirror.openshift.com/pub/openshift-v4/clients/ocp/[OpenShift mirror downloads^] site.
The version of `openshift-install` that you downloaded would know the exact images to retrieve for you during the install.
However, in a disconnected install you are doing it the other way around.
You already have the images and you need to make sure you use the correct version of the installer.
Instead of searching for the correct version and trying to download it from the Internet, you can extract it from the images you have already mirrored into your environment.
This guarantees you have the correct version.

. On your `bastion`, run the following command.
This will extract the `openshift-install` binary from images you have already mirrored.
The `openshift-install` binary will then exist and be executable on your `bastion`.
This ensures you have a version of the installer that matches the payload and images your downloaded.
+
[source,sh]
----
cd $HOME

oc adm release extract -a ${LOCAL_SECRET_JSON} --command=openshift-install "${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}:${OCP_RELEASE}-${ARCHITECTURE}"

ls -l
----
+
.Sample Output
[source,sh,options="nowrap"]
----
drwxrwxr-x. 6 lab-user root        105 Nov 25 07:44 certbot
drwxrwxr-x. 2 lab-user root         79 Nov 25 07:45 certificates
-rw-r--r--. 1 lab-user users      2821 Nov 25 12:20 merged_pullsecret.json
-rw-r--r--. 1 lab-user users      2751 Nov 25 12:20 ocp_pullsecret.json
-rw-r--r--. 1 lab-user users  52556789 Oct 26 12:59 openshift-client-linux-4.11.11.tar.gz
-rwxr-xr-x. 1 lab-user users 483639296 Oct 21 11:25 openshift-install
-rw-------. 1 lab-user users        99 Nov 25 12:18 pullsecret_config.json
drwxr--r--. 2 lab-user users      4096 Nov 25 07:43 resources
drwxr-xr-x. 3 lab-user users        21 Nov 25 07:43 virtualenvs
----

. Copy this file to a location that is in your `$PATH` and will make it easier to use.
+
[source,sh]
----
sudo mv openshift-install /usr/local/sbin

sudo chown root:root /usr/local/sbin/openshift-install
----

. Validate that your `openshift-install` is executable and that you are running an expected version pulled from an expected location.
+
[source,sh]
----
openshift-install version
----
+
.Sample Output
[source,sh,options="nowrap"]
----
openshift-install 4.11.11
built from commit 9d1e216a2ac5fede74450d1383c990ecc97c59da
release image utilityvm.smp1235.internal:5000/ocp4/openshift4@sha256:eb84d8fa95d323a20ce80a518cfd2cc87da5b8f0c89204874f73ee05e24344d9
release architecture amd64
----

. Now that you have the installer, you are ready to begin continuing the preparation for your installation.
Before you proceed, think about everything you will need before you can start your first server in the bootstrap process.
Create a directory to hold all of your installation artifacts required for installation.
+
[source,sh]
----
mkdir -p $HOME/aws-upi
cd $HOME/aws-upi
----

. Create the installation artifacts that satisfy the following requirements:
+
* An `install-config.yaml` that has the following defined:
** Deploys *zero* compute machines
** Has an alternate source for images in `imageContentSources`
** Provides a certificate for local container registry in `additionalTrustBundle`
** A merged pull secret with credentials to both Red Hat registries and local container registry
** The SSH key in your user's `.ssh` directory
** A base domain of `sandboxXXXX.opentlc.com` (from your provisioning e-mail)
** A cluster name of `cluster-$GUID`
** Master & bootstrap should use an instance type of `m5.xlarge`, which will provide 4 vCPU and 16Gi memory
** The CIDR for the machineNetwork should be *10.0.0.0/16*.
+
NOTE: You can reference the link:https://docs.openshift.com/container-platform/4.11/installing/installing_aws/installing-restricted-networks-aws-installer-provisioned.html[Openshift docs^] for some hints.

ifeval::[{show_solution} == true]

. Begin by collecting the information you will need.
. Before you run the `openshift-install` command, find the top level DNS domain you will be using. You will find that in the provisioning e-mail (e.g. `sandboxXXXX.opentlc.com`).
. Remind yourself of your merged pull secret:
+
[source,sh]
----
cat $HOME/merged_pullsecret.json
----

. Get the CA Certificate for the registry (the `sed` command adds two spaces at the beginning of each line making it easier to paste to the install-config.yaml):
+
[source,sh]
----
cat /etc/pki/ca-trust/source/anchors/ca.pem | sed -e 's/^/  /'
----

. Run `openshift-install` to create your `install-config.yaml` file. Answer the questions using the information you have gathered.
+
[source,sh]
----
openshift-install create install-config --dir $HOME/aws-upi
----
+
.Sample Output
[source,sh]
----
? SSH Public Key /home/nstephan-redhat.com/.ssh/${GUID}key.pub
? Platform aws
? Region us-east-2
? Base Domain sandboxNNNN.opentlc.com <<<< Your sandbox ID
? Cluster Name cluster-$GUID
? Pull Secret [? for help] *********** <<<< Put the content of your merged_pullsecret.json file.
----

. Edit your generated `install-config.yaml` to update additional values as specified in the requirements.
Your final `install-config.yaml` should look like this example.

+
TIP: Make sure you follow `yaml` standards for indentation spacing.
That means 2 spaces at a time.
Before copying the content you can add the 2 SPACES.
Before saving the file, verify that the yaml is parseable.
You can use any parser tool.
Maybe try: https://yamlchecker.com/

+
[source,options="nowrap"]
----
apiVersion: v1
baseDomain: sandboxNNNN.opentlc.com
compute:
- architecture: amd64
  hyperthreading: Enabled
  name: worker
  platform: {}
  replicas: 0 <1>
controlPlane:
  architecture: amd64
  hyperthreading: Enabled
  name: master
  platform: <2>
    aws:
      type: m5.xlarge
  replicas: 3
metadata:
  creationTimestamp: null
  name: cluster-GUID <3>
networking:
  clusterNetwork:
  - cidr: 10.128.0.0/14
    hostPrefix: 23
  machineNetwork:
  - cidr: 10.0.0.0/16 <4>
  networkType: OpenShiftSDN
  serviceNetwork:
  - 172.30.0.0/16
platform:
  aws:
    region: us-east-2
publish: External
pullSecret: '<your json merged pull secret>' <5>
sshKey: |
  ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC9gjWmsgsM89mt07lRFBO4Pkg6wofTum13m/dOvcsg7R84pKy7DJpxXfKG1e5HeYd3VixPdqkbXKaQBmR4XQkFOCpo1akP4e8dP2PRYvIBHSkCyRDDt2wwExmRr788h/dG7ikreWLOdRyuTfdEkVc2I2cFz1tgFZAq9ypwofVN2VKse42QxPZAxM41Dgx0mBsoOhQbI/AUbe/KrCvZsD2VvjTQpYkkoyalC3FGt0pZSS/8Mq1dTFFZrLXfrrN04OBE/ZrC/DmOwVbMMJ+eHaif30FFbRNgIE0Anu2hO80uC3VwJRe/GI6WDlFTWKOa6eYvcZfDMHv1r5DH2oOUhEYB soupy@Soupy-Sales-MacBook-Chicken
imageContentSources: <6>
- mirrors:
  - utilityvm.GUID.internal:5000/ocp4/openshift4
  source: quay.io/openshift-release-dev/ocp-release
- mirrors:
  - utilityvm.GUID.internal:5000/ocp4/openshift4
  source: quay.io/openshift-release-dev/ocp-v4.0-art-dev
additionalTrustBundle: | <7>
  -----BEGIN CERTIFICATE-----
  MIIDhDCCAmygAwIBAgIUPYb4tIVKwfLulG+7n1SVE4iUlDowDQYJKoZIhvcNAQEL
  BQAwWjELMAkGA1UEBhMCVVMxEzARBgNVBAgTCldhc2hpbmd0b24xEDAOBgNVBAcT
  B1NlYXR0bGUxDTALBgNVBAsTBEdQVEUxFTATBgNVBAMTDFJlZCBIYXQgR1BURTAe
  Fw0yMTAyMTcyMTAyMDBaFw0yNjAyMTYyMTAyMDBaMFoxCzAJBgNVBAYTAlVTMRMw
  EQYDVQQIEwpXYXNoaW5ndG9uMRAwDgYDVQQHEwdTZWF0dGxlMQ0wCwYDVQQLEwRH
  UFRFMRUwEwYDVQQDEwxSZWQgSGF0IEdQVEUwggEiMA0GCSqGSIb3DQEBAQUAA4IB
  DwAwggEKAoIBAQC9lzPgDSQANEv7DchTgpA6etKO7JV+azv89sWaMWBnFG/Z0mV5
  fD7OzojrJ50JGgFBPVUr9+pkHFpwusAqhjBpn68Z+jgak+WkJTOzP1rZZfHS5TOm
  vsRS1V40lhxIMp78mmZIy9TKYlDL1px9+bND7NYE2urtTanDaMOEeeYMmUuNNpaD
  I00qKh7oUzbVa/pAb2GjzrC9OVDYXHOpqGtiOPPXTcPFIdOiNNDUVrPiZt/O4svU
  VeAs9BouVrIELouIbZv0P9df83QwgK5hdXKm4yIOrjU3WCvqv4UFmMr96ci7pQhD
  btzJvJm3lhXz1pKdpLVaMOdaMLGQlqCMBQ7rAgMBAAGjQjBAMA4GA1UdDwEB/wQE
  AwIBBjAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBS4Glio37SbH7nXYL2bwdx7
  rDXmOTANBgkqhkiG9w0BAQsFAAOCAQEAUn7mXM2PrJYeigY5qx7S+zV0qYdsdvRA
  7MLFpeHtrt3rdIr5Vha5bPs5Ulj4ZB/VK1iCZ251t2D1LvEHz9U6JsUZs5MR8mPB
  3IiwpY84gAOxj1c9TXcRRDGIavPYgol2Q4sFVDpXbNyish6uz+JC+RMRI+E5FEWX
  d+3wiRv/45Ft+It1gR3Loi4xkjmpc8ohkGqlrPPhrWruYNUcO+Y9YNpLcDtfKuol
  rPexpzDLWdusQKrMj7xSROeKdTrBktLXuVmnIisyT7kPCU1hQY+TWHviKLm0hFEY
  /wQoreUIsNQK/JLLnsd2bDQ+GsLjo3woCVzoG0IAV5wcNR9ucaenPQ==
  -----END CERTIFICATE-----
----
+
* A lot is happening in this file, let's review:
<1> The number of workers has been changed to *zero*.
This is a requirement for a UPI install and you will be adding workers manually later.
<2> This defines a specific `type` of machine, or flavor in OpenStack, to be used for openshift control plane nodes.
You can define a different type for masters & workers.
Additional types of machines can be added post installation.
<3> This is the name of your cluster. Remember to change the GUID value for your own GUID.
<4> The `MachineCIDR` is the subnet that you will use for your VM IP addresses.
This *must* match the subnet you'll create in the new VPC below.
<5> This is pull secret that includes credentials for the external registries and private container registry.
Both are included for ease of use in this lab, but you could define _only_ the pull secret for your private container registry if you intended on being fully disconnected.
<6> The `imageContentSources` comes from the mirroring command you ran earlier. Add this content, remember to change the GUID value for your own GUID.
This will tell the installation process (and cluster, once it is built) to redirect any image pulls for OpenShift components to this source.
<7> The `additionalTrustBundle` is the certificate that is required to securely pull the container images.
This will be added to your cluster for future pulls once the cluster is fully built.
You can retrieve this from the `/etc/pki/ca-trust/source/anchors/ca.pem` file.
+
TIP: Make sure you follow `YAML` standards for indentation spacing.
That means 2 spaces at a time.
Before copying the content you can add the 2 SPACES.
Before saving the file, verify that the yaml is parseable.
You can use any parser tool. For example: https://yaml-online-parser.appspot.com/
+
WARNING: DO NOT SKIP THE STEPS ABOVE.
If you miss something, you might not find out until near the end of the lab and then you will have to do all of this over again.
endif::[]

. Once your `install-config.yaml` is correct, make a backup copy of it.
It will be consumed in the next step and you might want to reference it or use it to start over if you make a mistake.
+
[source,sh]
----
mkdir -p $HOME/backup
cp $HOME/aws-upi/install-config.yaml $HOME/backup
----
. [[recovery]]Create the `manifests`.
This is the second stage of the installer that would normally happen and be hidden to you.
+
[source,sh]
----
openshift-install create manifests --dir $HOME/aws-upi
----
+
.Sample Output
[source,sh,options="nowrap"]
----
INFO Credentials loaded from the "default" profile in file "/home/varodrig-redhat.com/.aws/credentials"
INFO Consuming Install Config from target directory
WARNING Making control-plane schedulable by setting MastersSchedulable to true for Scheduler cluster settings
INFO Manifests created in: /home/varodrig-redhat.com/aws-upi/manifests and /home/varodrig-redhat.com/aws-upi/openshift
----

. Look at the files created by `openshift-install`.
A `manifest` is basically a definition of a Kubernetes object.
In this list, you will have a number of "Core" manifests to begin bootstrapping the cluster.
In addition, you'll have some OpenShift specific manifests.
+
----
tree
----
+
.Sample Output
[source,sh,options="nowrap"]
----
.
|-- manifests
|   |-- 04-openshift-machine-config-operator.yaml
|   |-- cloud-provider-config.yaml
|   |-- cluster-config.yaml
|   |-- cluster-dns-02-config.yml
|   |-- cluster-infrastructure-02-config.yml
|   |-- cluster-ingress-02-config.yml
|   |-- cluster-network-01-crd.yml
|   |-- cluster-network-02-config.yml
|   |-- cluster-proxy-01-config.yaml
|   |-- cluster-scheduler-02-config.yml
|   |-- cvo-overrides.yaml
|   |-- etcd-ca-bundle-configmap.yaml
|   |-- etcd-client-secret.yaml
|   |-- etcd-metric-client-secret.yaml
|   |-- etcd-metric-serving-ca-configmap.yaml
|   |-- etcd-metric-signer-secret.yaml
|   |-- etcd-namespace.yaml
|   |-- etcd-service.yaml
|   |-- etcd-serving-ca-configmap.yaml
|   |-- etcd-signer-secret.yaml
|   |-- image-content-source-policy-0.yaml
|   |-- image-content-source-policy-1.yaml
|   |-- kube-cloud-config.yaml
|   |-- kube-system-configmap-root-ca.yaml
|   |-- machine-config-server-tls-secret.yaml
|   |-- openshift-config-secret-pull-secret.yaml
|   `-- user-ca-bundle-config.yaml
`-- openshift
    |-- 99_cloud-creds-secret.yaml
    |-- 99_kubeadmin-password-secret.yaml
    |-- 99_openshift-cluster-api_master-machines-0.yaml
    |-- 99_openshift-cluster-api_master-machines-1.yaml
    |-- 99_openshift-cluster-api_master-machines-2.yaml
    |-- 99_openshift-cluster-api_master-user-data-secret.yaml
    |-- 99_openshift-cluster-api_worker-machineset-0.yaml
    |-- 99_openshift-cluster-api_worker-user-data-secret.yaml
    |-- 99_openshift-machineconfig_99-master-ssh.yaml
    |-- 99_openshift-machineconfig_99-worker-ssh.yaml
    |-- 99_role-cloud-creds-secret-reader.yaml
    `-- openshift-install-manifests.yaml

2 directories, 40 files
----

. Typically, you are not expected to and discouraged from modifying the `manifests`.
In a UPI install, you do need to make a few modifications.
For this install, you need to make two changes:
.. Set the masters to unschedulable.
This ensures that workloads such as `ingress controllers` won't try and fail to run on the master nodes.
+
ifeval::[{show_solution} == true]

[source,sh]
----
ansible localhost -m lineinfile -a 'path="$HOME/aws-upi/manifests/cluster-scheduler-02-config.yml" regexp="^  mastersSchedulable" line="  mastersSchedulable: false"'

cat $HOME/aws-upi/manifests/cluster-scheduler-02-config.yml
----
+
.Sample Output
[source,sh]
----
apiVersion: config.openshift.io/v1
kind: Scheduler
metadata:
  creationTimestamp: null
  name: cluster
spec:
  mastersSchedulable: false
  policy:
    name: ""
status: {}
----

endif::[]
+
.. Remove the manifest that would create the `master` machines.
You will be creating these manually later in this lab as part of the UPI installation.
Do not erase the worker machineset manifests.
They won't be deployed because the compute replica count is 0 in the install-config.yaml, and we'll be using them later as a template for machinesets.
+
[source,sh]
----
rm -f openshift/99_openshift-cluster-api_master-machines-*.yaml
----

. Once your `manifests` are correctly modified, you are ready to move onto the last phase of preparation.
Create your `ignition` files.
Remember, the `ignition` files are what is used to help configure Red Hat Enterprise Linux CoreOS (RHCOS) on boot.
+
[source,sh]
----
openshift-install create ignition-configs --dir $HOME/aws-upi
----
+
.Sample Output
[source,sh]
----
INFO Consuming Worker Machines from target directory
INFO Consuming OpenShift Install (Manifests) from target directory
INFO Consuming Openshift Manifests from target directory
INFO Consuming Common Manifests from target directory
INFO Consuming Master Machines from target directory
INFO Ignition-Configs created in: /home/gmontalv-redhat.com/aws-upi and /home/gmontalv-redhat.com/aws-upi/auth
----

. Look at the new files created.
This is what you need to boot your cluster, but you still need to make a few more changes.
Like `manifests`, `ignition` files are not something you are normally expected to modify.
To complete a disconnected UPI install on AWS, you do need to make a couple of changes.
+
[source,sh]
----
tree
----
+
.Sample Output
[source,sh]
----
.
├── auth
│   ├── kubeadmin-password
│   └── kubeconfig
├── bootstrap.ign
├── master.ign
├── metadata.json
└── worker.ign

1 directory, 6 files
----

. Set an environment variable for your `INFRA_ID`.
This will make it easier to work with some of the subsequent commands in this lab.
+
[source,sh]
----
ansible localhost -m lineinfile -a 'path=$HOME/.bashrc regexp="^export INFRA_ID" line="export INFRA_ID=$(jq -r .infraID $HOME/aws-upi/metadata.json)"'

source $HOME/.bashrc
----

. Make sure your `$INFRA_ID` was set properly.
It should look similar to this.
+
[source,sh]
----
echo $INFRA_ID
----
+
.Sample Output
[source,sh]
----
cluster-3be3-rswmg
----

. `Ignition` can be a bit difficult to work with since you can't add to it in plain text.
The data must be properly encoded and added to the `ignition` file.

*Congratulations!* This was a long phase, but you are finished with your preparation work.

You have completed the following:

* Deployed and configured a local container registry
* Mirrored all required OpenShift container images to your local container registry
* Created custom `install-config.yaml`
* Customized the `manifests` as necessary for AWS UPI
* Created the `ignition` files
